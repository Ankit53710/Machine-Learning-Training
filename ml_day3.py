# -*- coding: utf-8 -*-
"""ML day3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ctGlYjfMBmBttYBJ-DEAvGPqcUo1csvl

**Deep Learning**
"""

#deep neural network of diabetes
from sklearn.datasets import load_diabetes
ld=load_diabetes()

x=ld.data
y=ld.target
from sklearn.preprocessing import StandardScaler
ss=StandardScaler()
x1=ss.fit_transform(x)
from sklearn.model_selection import train_test_split
xtrain,xtest,ytrain,ytest=train_test_split(x1,y,test_size=0.2)

#dense layer
#making sequential model of deep neural
from keras.models import Sequential
from keras.callbacks import EarlyStopping#day 6
from keras.layers import Dense

model=Sequential()
model.add(Dense(12,activation='relu',input_dim=10))
model.add(Dense(12,activation='relu'))
model.add(Dense(5,activation='relu'))
model.add(Dense(1,activation='relu'))
model.compile(optimizer='adam',loss='mean_squared_error')
es=EarlyStopping(monitor='loss',min_delta=0.001,patience=2,mode='auto')#day 6

hs=model.fit(xtrain,ytrain,callbacks=[es],epochs=1000)#day 6 xtrain,ytrain,validation_data(xtest,ytest)
hs.history.keys()
hs1=model.fit(xtest,ytest,callbacks=[es],epochs=1000)

import matplotlib.pyplot as plt
plt.plot(hs.history['loss'])
plt.legend(['loss'])

plt.plot(hs1.history['loss'],c='red')

ypred=model.predict(xtest)

from sklearn.metrics import r2_score
r2_score(ytest,ypred)

#exponetial dataset model

from google.colab import files
uploaded=files.upload()

import pandas as pd
df=pd.read_excel(uploaded['exponential dataset.xlsx'])
x=df['input']
y=df['output']

import matplotlib.pyplot as plt
plt.scatter(x,y)

import numpy as np
import math as mt
from numpy.random import randint
x=[]
y=[]
for i in  range(100):
  a=randint(20,100)
  b=mt.exp(a)
  x.append(a)
  y.append(b)
y

import matplotlib.pyplot as plt
plt.scatter(x,y)

xarr=np.array(x)
yarr=np.array(y)
xnew=xarr.reshape(-1,1)
ynew=yarr.reshape(-1,1)
from keras.models import Sequential
from keras.layers import Dense
model=Sequential()
model.add(Dense(4,activation='relu',input_dim=1))
model.add(Dense(4,activation='relu'))
model.add(Dense(1,activation='relu'))
model.compile(optimizer='adam',loss='mean_squared_error')
model.fit(x,y,epochs=200)
ypred=model.predict(x)
plt.scatter(x,y)
plt.plot(y,ypred)

#classicification load_iris dataset
from sklearn.datasets import load_iris
li=load_iris()
x=li.data
y=li.target
from sklearn.preprocessing import MinMaxScaler
scale=MinMaxScaler()
x1=scale.fit_transform(x)

#Onehot Encoding
from sklearn.preprocessing import OneHotEncoder
import numpy as np
newy=np.array(y)
a=OneHotEncoder()
newy=a.fit_transform(newy[:,np.newaxis]).toarray()
newy1=newy.astype('int')

from keras.activations import softmax
from keras.callbacks import EarlyStopping#day 6
from sklearn.model_selection import train_test_split
xtrain,xtest,ytrain,ytest=train_test_split(x1,newy1,test_size=0.2)
from keras.models import Sequential
from keras.layers import Dense
model=Sequential()
model.add(Dense(12,activation='relu',input_dim=4))
model.add(Dense(12,activation='relu'))
model.add(Dense(3,activation='Softmax'))
model.compile(optimizer='adam',loss='categorical_crossentropy')#if binary class=binary crossentropy &spares_categorical_crossentropy for without Onehotcoding
es=EarlyStopping(monitor='accuracy',min_delta=0.01,patience=3,mode='auto')#day
model.fit(xtrain,ytrain,callbacks=[es],epochs=100)

ypred=model.predict(xtest)
ypred

for j in ypred:
  for i in j:
    if i>0.5:
      print(1,end=' ')
    else:
      print(0,end=' ')
  print("\n")

for i in range(len(ypred)):
  j=np.argmax(ypred[i,:])#argmax return highest value index
  ypred[i,0]=0
  ypred[i,1]=0
  ypred[i,2]=0
  ypred[i,j]=1


ypred.astype('int')

from sklearn.metrics import precision_score
precision_score([1,0,0],[1,1,1])
sum=0
for i in range(len(ypred)):
  a=precision_score(ytest[i],ypred[i])
  sum+=a
sum/=len(ypred)
sum

from sklearn.metrics import accuracy_score
accuracy_score(ytest,ypred)

from sklearn.metrics import recall_score
recall_score([1,0,0],[1,1,1])
sum=0
for i in range(len(ypred)):
  a=recall_score(ytest[i],ypred[i])
  sum+=a
sum/=len(ypred)
sum

from sklearn.metrics import f1_score
sum=0
for i  in range(len(ypred)):
  j==0